{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset clue/cmnli to /home/mymusise/.cache/huggingface/datasets/clue/cmnli/1.0.0/e508b66266ba417d60e89ed8b167699cb4b56d3a2ead29b5667907d08069dbfc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 31.4M/31.4M [00:05<00:00, 5.62MB/s]\n",
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset clue downloaded and prepared to /home/mymusise/.cache/huggingface/datasets/clue/cmnli/1.0.0/e508b66266ba417d60e89ed8b167699cb4b56d3a2ead29b5667907d08069dbfc. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 616.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"clue\", \"cmnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = set(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'CpmTokenizer'. \n",
      "The class this function is called from is 'XLNetTokenizer'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "model_path = \"/data2/CPM-distill/CPM-Generate-distill\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391783/391783 [03:12<00:00, 2034.72ex/s]\n",
      "100%|██████████| 12241/12241 [00:06<00:00, 1989.36ex/s]\n"
     ]
    }
   ],
   "source": [
    "def token_map(examples):\n",
    "    return tokenizer(examples[\"sentence1\"] + examples[\"sentence2\"], padding=\"max_length\", max_length=512, truncation=True, add_special_tokens=False)\n",
    "\n",
    "train_dataset = dataset['train'].map(token_map)\n",
    "eval_dataset = dataset['validation'].map(token_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(seed=42)\n",
    "eval_dataset = eval_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /data2/CPM-distill/CPM-Generate-distill were not used when initializing GPT2ForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at /data2/CPM-distill/CPM-Generate-distill and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=len(labels)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure some model padding token id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: sentence1, idx, sentence2. If sentence1, idx, sentence2 are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12241\n",
      "  Batch size = 8\n",
      "100%|██████████| 1531/1531 [01:44<00:00, 14.72it/s]\n",
      "The following columns in the training set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: sentence1, idx, sentence2. If sentence1, idx, sentence2 are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/mymusise/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 391783\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train: {'eval_loss': 1.2480762004852295, 'eval_accuracy': 0.3397598235438281, 'eval_runtime': 104.0964, 'eval_samples_per_second': 117.593, 'eval_steps_per_second': 14.708}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 500/73461 [03:00<7:55:02,  2.56it/s]Saving model checkpoint to test_trainer/checkpoint-500\n",
      "Configuration saved in test_trainer/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1339, 'learning_rate': 4.96596833694069e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-500/pytorch_model.bin\n",
      "  1%|▏         | 1000/73461 [06:01<7:21:12,  2.74it/s]Saving model checkpoint to test_trainer/checkpoint-1000\n",
      "Configuration saved in test_trainer/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1141, 'learning_rate': 4.9319366738813796e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-1000/pytorch_model.bin\n",
      "  2%|▏         | 1500/73461 [09:00<6:49:43,  2.93it/s] Saving model checkpoint to test_trainer/checkpoint-1500\n",
      "Configuration saved in test_trainer/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.111, 'learning_rate': 4.8979050108220693e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-1500/pytorch_model.bin\n",
      "  3%|▎         | 2000/73461 [11:55<6:49:38,  2.91it/s] Saving model checkpoint to test_trainer/checkpoint-2000\n",
      "Configuration saved in test_trainer/checkpoint-2000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1072, 'learning_rate': 4.8638733477627584e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-2000/pytorch_model.bin\n",
      "  3%|▎         | 2500/73461 [14:49<6:48:47,  2.89it/s] Saving model checkpoint to test_trainer/checkpoint-2500\n",
      "Configuration saved in test_trainer/checkpoint-2500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1071, 'learning_rate': 4.829841684703448e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-2500/pytorch_model.bin\n",
      "  4%|▍         | 3000/73461 [17:43<6:42:14,  2.92it/s] Saving model checkpoint to test_trainer/checkpoint-3000\n",
      "Configuration saved in test_trainer/checkpoint-3000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1039, 'learning_rate': 4.7958100216441385e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-3000/pytorch_model.bin\n",
      "  5%|▍         | 3500/73461 [20:37<6:41:10,  2.91it/s] Saving model checkpoint to test_trainer/checkpoint-3500\n",
      "Configuration saved in test_trainer/checkpoint-3500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1072, 'learning_rate': 4.7617783585848275e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-3500/pytorch_model.bin\n",
      "  5%|▌         | 4000/73461 [23:31<6:36:49,  2.92it/s] Saving model checkpoint to test_trainer/checkpoint-4000\n",
      "Configuration saved in test_trainer/checkpoint-4000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0935, 'learning_rate': 4.727746695525517e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-4000/pytorch_model.bin\n",
      "  6%|▌         | 4500/73461 [26:25<6:36:33,  2.90it/s] Saving model checkpoint to test_trainer/checkpoint-4500\n",
      "Configuration saved in test_trainer/checkpoint-4500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0511, 'learning_rate': 4.693715032466207e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-4500/pytorch_model.bin\n",
      "  7%|▋         | 5000/73461 [29:19<6:31:26,  2.91it/s] Saving model checkpoint to test_trainer/checkpoint-5000\n",
      "Configuration saved in test_trainer/checkpoint-5000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0252, 'learning_rate': 4.6596833694068966e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-5000/pytorch_model.bin\n",
      "  7%|▋         | 5500/73461 [32:13<6:29:23,  2.91it/s] Saving model checkpoint to test_trainer/checkpoint-5500\n",
      "Configuration saved in test_trainer/checkpoint-5500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0132, 'learning_rate': 4.625651706347586e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-5500/pytorch_model.bin\n",
      "  8%|▊         | 6000/73461 [35:07<6:26:53,  2.91it/s] Saving model checkpoint to test_trainer/checkpoint-6000\n",
      "Configuration saved in test_trainer/checkpoint-6000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0074, 'learning_rate': 4.591620043288275e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-6000/pytorch_model.bin\n",
      "  9%|▉         | 6500/73461 [38:00<6:23:25,  2.91it/s] Saving model checkpoint to test_trainer/checkpoint-6500\n",
      "Configuration saved in test_trainer/checkpoint-6500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0066, 'learning_rate': 4.557588380228966e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-6500/pytorch_model.bin\n",
      " 10%|▉         | 7000/73461 [40:54<6:22:19,  2.90it/s] Saving model checkpoint to test_trainer/checkpoint-7000\n",
      "Configuration saved in test_trainer/checkpoint-7000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.004, 'learning_rate': 4.523556717169655e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-7000/pytorch_model.bin\n",
      " 10%|█         | 7500/73461 [43:48<6:14:35,  2.93it/s] Saving model checkpoint to test_trainer/checkpoint-7500\n",
      "Configuration saved in test_trainer/checkpoint-7500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0014, 'learning_rate': 4.4895250541103444e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-7500/pytorch_model.bin\n",
      " 11%|█         | 8000/73461 [46:41<6:15:26,  2.91it/s] Saving model checkpoint to test_trainer/checkpoint-8000\n",
      "Configuration saved in test_trainer/checkpoint-8000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.001, 'learning_rate': 4.455493391051034e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-8000/pytorch_model.bin\n",
      " 12%|█▏        | 8500/73461 [49:35<6:09:49,  2.93it/s] Saving model checkpoint to test_trainer/checkpoint-8500\n",
      "Configuration saved in test_trainer/checkpoint-8500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.996, 'learning_rate': 4.421461727991724e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-8500/pytorch_model.bin\n",
      " 12%|█▏        | 9000/73461 [52:28<6:10:25,  2.90it/s] Saving model checkpoint to test_trainer/checkpoint-9000\n",
      "Configuration saved in test_trainer/checkpoint-9000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9842, 'learning_rate': 4.3874300649324135e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-9000/pytorch_model.bin\n",
      " 13%|█▎        | 9500/73461 [55:22<6:11:43,  2.87it/s] Saving model checkpoint to test_trainer/checkpoint-9500\n",
      "Configuration saved in test_trainer/checkpoint-9500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0031, 'learning_rate': 4.3533984018731026e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-9500/pytorch_model.bin\n",
      " 14%|█▎        | 10000/73461 [58:16<6:02:52,  2.91it/s]Saving model checkpoint to test_trainer/checkpoint-10000\n",
      "Configuration saved in test_trainer/checkpoint-10000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.989, 'learning_rate': 4.319366738813793e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-10000/pytorch_model.bin\n",
      " 14%|█▍        | 10500/73461 [1:01:09<5:59:26,  2.92it/s]Saving model checkpoint to test_trainer/checkpoint-10500\n",
      "Configuration saved in test_trainer/checkpoint-10500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9882, 'learning_rate': 4.285335075754482e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-10500/pytorch_model.bin\n",
      " 15%|█▍        | 11000/73461 [1:04:03<6:01:00,  2.88it/s] Saving model checkpoint to test_trainer/checkpoint-11000\n",
      "Configuration saved in test_trainer/checkpoint-11000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9841, 'learning_rate': 4.2513034126951717e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-11000/pytorch_model.bin\n",
      " 16%|█▌        | 11500/73461 [1:06:56<5:53:52,  2.92it/s] Saving model checkpoint to test_trainer/checkpoint-11500\n",
      "Configuration saved in test_trainer/checkpoint-11500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9842, 'learning_rate': 4.2172717496358614e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-11500/pytorch_model.bin\n",
      " 16%|█▋        | 12000/73461 [1:09:49<5:54:40,  2.89it/s] Saving model checkpoint to test_trainer/checkpoint-12000\n",
      "Configuration saved in test_trainer/checkpoint-12000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9825, 'learning_rate': 4.183240086576551e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-12000/pytorch_model.bin\n",
      " 17%|█▋        | 12500/73461 [1:12:42<5:50:50,  2.90it/s] Saving model checkpoint to test_trainer/checkpoint-12500\n",
      "Configuration saved in test_trainer/checkpoint-12500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9711, 'learning_rate': 4.149208423517241e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-12500/pytorch_model.bin\n",
      " 18%|█▊        | 13000/73461 [1:15:36<5:42:44,  2.94it/s] Saving model checkpoint to test_trainer/checkpoint-13000\n",
      "Configuration saved in test_trainer/checkpoint-13000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9753, 'learning_rate': 4.11517676045793e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-13000/pytorch_model.bin\n",
      " 18%|█▊        | 13500/73461 [1:18:29<5:45:50,  2.89it/s] Saving model checkpoint to test_trainer/checkpoint-13500\n",
      "Configuration saved in test_trainer/checkpoint-13500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9793, 'learning_rate': 4.0811450973986195e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-13500/pytorch_model.bin\n",
      " 19%|█▉        | 14000/73461 [1:21:22<5:42:44,  2.89it/s] Saving model checkpoint to test_trainer/checkpoint-14000\n",
      "Configuration saved in test_trainer/checkpoint-14000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9705, 'learning_rate': 4.04711343433931e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-14000/pytorch_model.bin\n",
      " 20%|█▉        | 14500/73461 [1:24:16<5:38:20,  2.90it/s] Saving model checkpoint to test_trainer/checkpoint-14500\n",
      "Configuration saved in test_trainer/checkpoint-14500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.985, 'learning_rate': 4.013081771279999e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-14500/pytorch_model.bin\n",
      " 20%|██        | 15000/73461 [1:27:09<5:32:31,  2.93it/s] Saving model checkpoint to test_trainer/checkpoint-15000\n",
      "Configuration saved in test_trainer/checkpoint-15000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.964, 'learning_rate': 3.9790501082206886e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-15000/pytorch_model.bin\n",
      " 21%|██        | 15500/73461 [1:30:02<5:37:27,  2.86it/s] Saving model checkpoint to test_trainer/checkpoint-15500\n",
      "Configuration saved in test_trainer/checkpoint-15500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9635, 'learning_rate': 3.945018445161378e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-15500/pytorch_model.bin\n",
      " 22%|██▏       | 16000/73461 [1:32:55<5:29:07,  2.91it/s] Saving model checkpoint to test_trainer/checkpoint-16000\n",
      "Configuration saved in test_trainer/checkpoint-16000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9672, 'learning_rate': 3.910986782102068e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-16000/pytorch_model.bin\n",
      " 22%|██▏       | 16500/73461 [1:35:48<5:30:38,  2.87it/s] Saving model checkpoint to test_trainer/checkpoint-16500\n",
      "Configuration saved in test_trainer/checkpoint-16500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9683, 'learning_rate': 3.876955119042758e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-16500/pytorch_model.bin\n",
      " 23%|██▎       | 17000/73461 [1:38:42<5:27:43,  2.87it/s] Saving model checkpoint to test_trainer/checkpoint-17000\n",
      "Configuration saved in test_trainer/checkpoint-17000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9679, 'learning_rate': 3.842923455983447e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-17000/pytorch_model.bin\n",
      " 24%|██▍       | 17500/73461 [1:41:35<5:17:41,  2.94it/s] Saving model checkpoint to test_trainer/checkpoint-17500\n",
      "Configuration saved in test_trainer/checkpoint-17500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9533, 'learning_rate': 3.808891792924137e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-17500/pytorch_model.bin\n",
      " 25%|██▍       | 18000/73461 [1:44:28<5:17:01,  2.92it/s] Saving model checkpoint to test_trainer/checkpoint-18000\n",
      "Configuration saved in test_trainer/checkpoint-18000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9576, 'learning_rate': 3.774860129864826e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-18000/pytorch_model.bin\n",
      " 25%|██▌       | 18500/73461 [1:47:22<5:15:54,  2.90it/s] Saving model checkpoint to test_trainer/checkpoint-18500\n",
      "Configuration saved in test_trainer/checkpoint-18500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9542, 'learning_rate': 3.740828466805516e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-18500/pytorch_model.bin\n",
      " 26%|██▌       | 19000/73461 [1:50:15<5:14:40,  2.88it/s] Saving model checkpoint to test_trainer/checkpoint-19000\n",
      "Configuration saved in test_trainer/checkpoint-19000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9405, 'learning_rate': 3.7067968037462055e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-19000/pytorch_model.bin\n",
      " 27%|██▋       | 19500/73461 [1:53:08<5:08:59,  2.91it/s] Saving model checkpoint to test_trainer/checkpoint-19500\n",
      "Configuration saved in test_trainer/checkpoint-19500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.939, 'learning_rate': 3.672765140686895e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-19500/pytorch_model.bin\n",
      " 27%|██▋       | 20000/73461 [1:56:02<5:06:12,  2.91it/s] Saving model checkpoint to test_trainer/checkpoint-20000\n",
      "Configuration saved in test_trainer/checkpoint-20000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9378, 'learning_rate': 3.638733477627585e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-20000/pytorch_model.bin\n",
      " 28%|██▊       | 20500/73461 [1:58:55<5:02:15,  2.92it/s] Saving model checkpoint to test_trainer/checkpoint-20500\n",
      "Configuration saved in test_trainer/checkpoint-20500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9391, 'learning_rate': 3.604701814568274e-05, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-20500/pytorch_model.bin\n",
      " 29%|██▊       | 21000/73461 [2:01:48<5:00:56,  2.91it/s] Saving model checkpoint to test_trainer/checkpoint-21000\n",
      "Configuration saved in test_trainer/checkpoint-21000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9369, 'learning_rate': 3.5706701515089644e-05, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-21000/pytorch_model.bin\n",
      " 29%|██▉       | 21500/73461 [2:04:42<5:01:48,  2.87it/s] Saving model checkpoint to test_trainer/checkpoint-21500\n",
      "Configuration saved in test_trainer/checkpoint-21500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.938, 'learning_rate': 3.536638488449654e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-21500/pytorch_model.bin\n",
      " 30%|██▉       | 22000/73461 [2:07:35<4:54:32,  2.91it/s] Saving model checkpoint to test_trainer/checkpoint-22000\n",
      "Configuration saved in test_trainer/checkpoint-22000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.93, 'learning_rate': 3.502606825390343e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-22000/pytorch_model.bin\n",
      " 31%|███       | 22500/73461 [2:10:28<4:50:26,  2.92it/s] Saving model checkpoint to test_trainer/checkpoint-22500\n",
      "Configuration saved in test_trainer/checkpoint-22500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9264, 'learning_rate': 3.468575162331033e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-22500/pytorch_model.bin\n",
      " 31%|███▏      | 23000/73461 [2:13:21<4:53:19,  2.87it/s] Saving model checkpoint to test_trainer/checkpoint-23000\n",
      "Configuration saved in test_trainer/checkpoint-23000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9183, 'learning_rate': 3.4345434992717225e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-23000/pytorch_model.bin\n",
      " 32%|███▏      | 23500/73461 [2:16:14<4:48:35,  2.89it/s] Saving model checkpoint to test_trainer/checkpoint-23500\n",
      "Configuration saved in test_trainer/checkpoint-23500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9349, 'learning_rate': 3.400511836212412e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-23500/pytorch_model.bin\n",
      " 33%|███▎      | 24000/73461 [2:19:07<4:41:37,  2.93it/s]Saving model checkpoint to test_trainer/checkpoint-24000\n",
      "Configuration saved in test_trainer/checkpoint-24000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9174, 'learning_rate': 3.366480173153102e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-24000/pytorch_model.bin\n",
      " 33%|███▎      | 24487/73461 [2:21:56<3:59:13,  3.41it/s] The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: sentence1, idx, sentence2. If sentence1, idx, sentence2 are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12241\n",
      "  Batch size = 8\n",
      "                                                         \n",
      " 33%|███▎      | 24487/73461 [2:23:34<3:59:13,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8857176899909973, 'eval_accuracy': 0.5863083081447594, 'eval_runtime': 97.9024, 'eval_samples_per_second': 125.033, 'eval_steps_per_second': 15.638, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 24500/73461 [2:23:39<10:12:14,  1.33it/s] Saving model checkpoint to test_trainer/checkpoint-24500\n",
      "Configuration saved in test_trainer/checkpoint-24500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9192, 'learning_rate': 3.3324485100937916e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-24500/pytorch_model.bin\n",
      " 34%|███▍      | 25000/73461 [2:26:32<4:37:23,  2.91it/s] Saving model checkpoint to test_trainer/checkpoint-25000\n",
      "Configuration saved in test_trainer/checkpoint-25000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8985, 'learning_rate': 3.298416847034481e-05, 'epoch': 1.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-25000/pytorch_model.bin\n",
      " 35%|███▍      | 25500/73461 [2:29:25<4:38:12,  2.87it/s]Saving model checkpoint to test_trainer/checkpoint-25500\n",
      "Configuration saved in test_trainer/checkpoint-25500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8876, 'learning_rate': 3.26438518397517e-05, 'epoch': 1.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-25500/pytorch_model.bin\n",
      " 35%|███▌      | 26000/73461 [2:32:19<4:31:54,  2.91it/s]Saving model checkpoint to test_trainer/checkpoint-26000\n",
      "Configuration saved in test_trainer/checkpoint-26000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8833, 'learning_rate': 3.23035352091586e-05, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-26000/pytorch_model.bin\n",
      " 36%|███▌      | 26500/73461 [2:35:12<4:27:44,  2.92it/s]Saving model checkpoint to test_trainer/checkpoint-26500\n",
      "Configuration saved in test_trainer/checkpoint-26500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8881, 'learning_rate': 3.1963218578565504e-05, 'epoch': 1.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-26500/pytorch_model.bin\n",
      " 37%|███▋      | 27000/73461 [2:38:06<4:29:02,  2.88it/s]Saving model checkpoint to test_trainer/checkpoint-27000\n",
      "Configuration saved in test_trainer/checkpoint-27000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8836, 'learning_rate': 3.1622901947972394e-05, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-27000/pytorch_model.bin\n",
      " 37%|███▋      | 27500/73461 [2:40:59<4:25:30,  2.89it/s]Saving model checkpoint to test_trainer/checkpoint-27500\n",
      "Configuration saved in test_trainer/checkpoint-27500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8776, 'learning_rate': 3.128258531737929e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-27500/pytorch_model.bin\n",
      " 38%|███▊      | 28000/73461 [2:43:52<4:19:16,  2.92it/s]Saving model checkpoint to test_trainer/checkpoint-28000\n",
      "Configuration saved in test_trainer/checkpoint-28000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8751, 'learning_rate': 3.094226868678619e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-28000/pytorch_model.bin\n",
      " 39%|███▉      | 28500/73461 [2:46:46<4:17:40,  2.91it/s]Saving model checkpoint to test_trainer/checkpoint-28500\n",
      "Configuration saved in test_trainer/checkpoint-28500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8882, 'learning_rate': 3.0601952056193085e-05, 'epoch': 1.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-28500/pytorch_model.bin\n",
      " 39%|███▉      | 29000/73461 [2:49:39<4:14:09,  2.92it/s]Saving model checkpoint to test_trainer/checkpoint-29000\n",
      "Configuration saved in test_trainer/checkpoint-29000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.861, 'learning_rate': 3.0261635425599982e-05, 'epoch': 1.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-29000/pytorch_model.bin\n",
      " 40%|████      | 29500/73461 [2:52:32<4:10:49,  2.92it/s]Saving model checkpoint to test_trainer/checkpoint-29500\n",
      "Configuration saved in test_trainer/checkpoint-29500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8706, 'learning_rate': 2.9921318795006876e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-29500/pytorch_model.bin\n",
      " 41%|████      | 30000/73461 [2:55:25<4:08:24,  2.92it/s]Saving model checkpoint to test_trainer/checkpoint-30000\n",
      "Configuration saved in test_trainer/checkpoint-30000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8598, 'learning_rate': 2.9581002164413773e-05, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-30000/pytorch_model.bin\n",
      " 42%|████▏     | 30500/73461 [2:58:19<4:08:21,  2.88it/s]Saving model checkpoint to test_trainer/checkpoint-30500\n",
      "Configuration saved in test_trainer/checkpoint-30500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8608, 'learning_rate': 2.9240685533820667e-05, 'epoch': 1.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-30500/pytorch_model.bin\n",
      " 42%|████▏     | 31000/73461 [3:01:12<4:01:51,  2.93it/s]Saving model checkpoint to test_trainer/checkpoint-31000\n",
      "Configuration saved in test_trainer/checkpoint-31000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8649, 'learning_rate': 2.8900368903227564e-05, 'epoch': 1.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-31000/pytorch_model.bin\n",
      " 43%|████▎     | 31500/73461 [3:04:05<4:00:27,  2.91it/s]Saving model checkpoint to test_trainer/checkpoint-31500\n",
      "Configuration saved in test_trainer/checkpoint-31500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8526, 'learning_rate': 2.8560052272634457e-05, 'epoch': 1.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-31500/pytorch_model.bin\n",
      " 44%|████▎     | 32000/73461 [3:06:58<4:00:23,  2.87it/s]Saving model checkpoint to test_trainer/checkpoint-32000\n",
      "Configuration saved in test_trainer/checkpoint-32000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8516, 'learning_rate': 2.8219735642041358e-05, 'epoch': 1.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-32000/pytorch_model.bin\n",
      " 44%|████▍     | 32500/73461 [3:09:51<3:53:23,  2.93it/s]Saving model checkpoint to test_trainer/checkpoint-32500\n",
      "Configuration saved in test_trainer/checkpoint-32500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8493, 'learning_rate': 2.7879419011448255e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-32500/pytorch_model.bin\n",
      " 45%|████▍     | 33000/73461 [3:12:45<3:51:27,  2.91it/s]Saving model checkpoint to test_trainer/checkpoint-33000\n",
      "Configuration saved in test_trainer/checkpoint-33000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8602, 'learning_rate': 2.753910238085515e-05, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-33000/pytorch_model.bin\n",
      " 46%|████▌     | 33500/73461 [3:15:38<3:52:34,  2.86it/s]Saving model checkpoint to test_trainer/checkpoint-33500\n",
      "Configuration saved in test_trainer/checkpoint-33500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8581, 'learning_rate': 2.7198785750262045e-05, 'epoch': 1.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-33500/pytorch_model.bin\n",
      " 46%|████▋     | 34000/73461 [3:18:31<3:46:45,  2.90it/s]Saving model checkpoint to test_trainer/checkpoint-34000\n",
      "Configuration saved in test_trainer/checkpoint-34000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8469, 'learning_rate': 2.685846911966894e-05, 'epoch': 1.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-34000/pytorch_model.bin\n",
      " 47%|████▋     | 34500/73461 [3:21:24<3:42:48,  2.91it/s]Saving model checkpoint to test_trainer/checkpoint-34500\n",
      "Configuration saved in test_trainer/checkpoint-34500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8463, 'learning_rate': 2.6518152489075836e-05, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-34500/pytorch_model.bin\n",
      " 48%|████▊     | 35000/73461 [3:24:18<3:40:22,  2.91it/s]Saving model checkpoint to test_trainer/checkpoint-35000\n",
      "Configuration saved in test_trainer/checkpoint-35000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.839, 'learning_rate': 2.6177835858482737e-05, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-35000/pytorch_model.bin\n",
      " 48%|████▊     | 35500/73461 [3:27:11<3:36:33,  2.92it/s]Saving model checkpoint to test_trainer/checkpoint-35500\n",
      "Configuration saved in test_trainer/checkpoint-35500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8453, 'learning_rate': 2.5837519227889627e-05, 'epoch': 1.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-35500/pytorch_model.bin\n",
      " 49%|████▉     | 36000/73461 [3:30:04<3:34:37,  2.91it/s]Saving model checkpoint to test_trainer/checkpoint-36000\n",
      "Configuration saved in test_trainer/checkpoint-36000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8338, 'learning_rate': 2.5497202597296527e-05, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-36000/pytorch_model.bin\n",
      " 50%|████▉     | 36500/73461 [3:32:57<3:31:57,  2.91it/s]Saving model checkpoint to test_trainer/checkpoint-36500\n",
      "Configuration saved in test_trainer/checkpoint-36500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8511, 'learning_rate': 2.515688596670342e-05, 'epoch': 1.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-36500/pytorch_model.bin\n",
      " 50%|█████     | 37000/73461 [3:35:50<3:29:02,  2.91it/s]Saving model checkpoint to test_trainer/checkpoint-37000\n",
      "Configuration saved in test_trainer/checkpoint-37000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8471, 'learning_rate': 2.4816569336110318e-05, 'epoch': 1.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-37000/pytorch_model.bin\n",
      " 51%|█████     | 37500/73461 [3:38:44<3:25:34,  2.92it/s]Saving model checkpoint to test_trainer/checkpoint-37500\n",
      "Configuration saved in test_trainer/checkpoint-37500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8473, 'learning_rate': 2.4476252705517215e-05, 'epoch': 1.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-37500/pytorch_model.bin\n",
      " 52%|█████▏    | 38000/73461 [3:41:37<3:21:50,  2.93it/s]Saving model checkpoint to test_trainer/checkpoint-38000\n",
      "Configuration saved in test_trainer/checkpoint-38000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8313, 'learning_rate': 2.413593607492411e-05, 'epoch': 1.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-38000/pytorch_model.bin\n",
      " 52%|█████▏    | 38500/73461 [3:44:30<3:20:36,  2.90it/s]Saving model checkpoint to test_trainer/checkpoint-38500\n",
      "Configuration saved in test_trainer/checkpoint-38500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8192, 'learning_rate': 2.379561944433101e-05, 'epoch': 1.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-38500/pytorch_model.bin\n",
      " 53%|█████▎    | 39000/73461 [3:47:23<3:15:57,  2.93it/s]Saving model checkpoint to test_trainer/checkpoint-39000\n",
      "Configuration saved in test_trainer/checkpoint-39000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8532, 'learning_rate': 2.3455302813737903e-05, 'epoch': 1.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-39000/pytorch_model.bin\n",
      " 54%|█████▍    | 39500/73461 [3:50:16<3:15:30,  2.89it/s]Saving model checkpoint to test_trainer/checkpoint-39500\n",
      "Configuration saved in test_trainer/checkpoint-39500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8295, 'learning_rate': 2.31149861831448e-05, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-39500/pytorch_model.bin\n",
      " 54%|█████▍    | 40000/73461 [3:53:10<3:11:26,  2.91it/s]Saving model checkpoint to test_trainer/checkpoint-40000\n",
      "Configuration saved in test_trainer/checkpoint-40000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8392, 'learning_rate': 2.2774669552551693e-05, 'epoch': 1.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-40000/pytorch_model.bin\n",
      " 55%|█████▌    | 40500/73461 [3:56:03<3:07:12,  2.93it/s]Saving model checkpoint to test_trainer/checkpoint-40500\n",
      "Configuration saved in test_trainer/checkpoint-40500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8246, 'learning_rate': 2.243435292195859e-05, 'epoch': 1.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-40500/pytorch_model.bin\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:300] . unexpected pos 92190016 vs 92189968",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:380\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 380\u001b[0m     _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:604\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    603\u001b[0m num_bytes \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39mnbytes()\n\u001b[0;32m--> 604\u001b[0m zip_file\u001b[39m.\u001b[39;49mwrite_record(name, storage\u001b[39m.\u001b[39;49mdata_ptr(), num_bytes)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 14\u001b[0m\n\u001b[1;32m      6\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m      7\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m      8\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbefore train: \u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mevaluate()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mafter train: \u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mevaluate()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:1497\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mepoch \u001b[39m=\u001b[39m epoch \u001b[39m+\u001b[39m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1495\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m-> 1497\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[1;32m   1498\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1499\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_substep_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:1628\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1625\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_to_hp_search(trial, epoch, metrics)\n\u001b[1;32m   1627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_save:\n\u001b[0;32m-> 1628\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_checkpoint(model, trial, metrics\u001b[39m=\u001b[39;49mmetrics)\n\u001b[1;32m   1629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_save(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:1730\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   1727\u001b[0m                 torch\u001b[39m.\u001b[39msave(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mstate_dict(), os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, SCALER_NAME))\n\u001b[1;32m   1728\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshould_save \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeepspeed:\n\u001b[1;32m   1729\u001b[0m     \u001b[39m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[0;32m-> 1730\u001b[0m     torch\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mstate_dict(), os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(output_dir, OPTIMIZER_NAME))\n\u001b[1;32m   1731\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings(record\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m caught_warnings:\n\u001b[1;32m   1732\u001b[0m         torch\u001b[39m.\u001b[39msave(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mstate_dict(), os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, SCHEDULER_NAME))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:381\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    380\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m--> 381\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    382\u001b[0m _legacy_save(obj, opened_file, pickle_module, pickle_protocol)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:260\u001b[0m, in \u001b[0;36m_open_zipfile_writer_buffer.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_like\u001b[39m.\u001b[39;49mwrite_end_of_file()\n\u001b[1;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer\u001b[39m.\u001b[39mflush()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:300] . unexpected pos 92190016 vs 92189968"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", per_device_train_batch_size=16)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "print(f\"before train: {trainer.evaluate()}\")\n",
    "trainer.train()\n",
    "print(f\"after train: {trainer.evaluate()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
